#!/usr/bin/env python3 
# encoding: utf-8
'''
PublishHandler -- AWS Lambda handler for publishing into a composite P2 repository hosted on S3

@copyright:  2021 Collins Aerospace. All rights reserved.

@license:    BSD 3-Clause License
'''

import boto3
import os
import json
import logging
import tempfile
import traceback
import zipfile

from boto3.session import Session
from s3tools.P2CompositeUtils import add_repository_to_composite

logger = logging.getLogger()
logger.setLevel(logging.INFO)

codepipeline_client = boto3.client('codepipeline')

def put_job_success(job_id):
    """Notify AWS CodePipeline of a successful job.

    Arguments:
        job_id {str} -- The unique ID for the job generated by AWS CodePipeline
    """
    logger.info('Putting job success')
    codepipeline_client.put_job_success_result(
        jobId=job_id,
        executionDetails={
            'summary': "Success",
            'percentComplete': 100
        }
    )

def put_job_failure(job_id, message):
    """Notify AWS CodePipeline of a successful job.

    Arguments:
        job_id {str} -- The unique ID for the job generated by AWS CodePipeline
    """
    logger.info('Putting job failure result=%s', message)
    codepipeline_client.put_job_success_result(
        jobId=job_id,
        executionDetails={
            'summary': "Failure: " + str(message),
            'percentComplete': 100
        }
    )

def extract_artifacts(s3, artifacts):
    """Extract the CodePipeline input artifacts from the artifact store
    
    Arguments:
        s3: S3 client at which to find the artifacts
        artifacts: The list of artifacts available to the function
    """
    logger.info('Extracting input artifacts...')
    for artifact in artifacts:
        tmp_file = tempfile.NamedTemporaryFile()
        bucket = artifact['location']['s3Location']['bucketName']
        key = artifact['location']['s3Location']['objectKey']
        logger.info('  extracting %s/%s', bucket, key)
        with tempfile.NamedTemporaryFile() as tmp_file:
            s3.download_file(bucket, key, tmp_file.name)
            with zipfile.ZipFile(tmp_file.name, 'r') as zip:
                zip.extractall()
    logger.info('Extracting input artifacts complete.')

def setup_s3_client(job_data):
    """Creates an S3 client
    
    Uses the credentials passed in the event by CodePipeline. These
    credentials can be used to access the artifact bucket.
    
    Args:
        job_data: The job data structure
        
    Returns:
        An S3 client with the appropriate credentials
        
    """
    key_id = job_data['artifactCredentials']['accessKeyId']
    key_secret = job_data['artifactCredentials']['secretAccessKey']
    session_token = job_data['artifactCredentials']['sessionToken']
    
    session = Session(aws_access_key_id=key_id,
        aws_secret_access_key=key_secret,
        aws_session_token=session_token)
    return session.client('s3', config=botocore.client.Config(signature_version='s3v4'))

def lambda_handler(event, context):
    logger.info('Context: %s', context)
    job_id = event['CodePipeline.job']['id']
    job_data = event['CodePipeline.job']['data']
    artifacts = job_data['inputArtifacts']
    if isinstance(event, dict):
        try:
            s3 = setup_s3_client(job_data)
            extract_artifacts(s3, artifacts)
            user_parameters = json.loads(event['CodePipeline.job']['data']['actionConfiguration']['configuration']['UserParameters'])
            add_repository_to_composite(user_parameters['inpath'], user_parameters['bucket_name'], user_parameters['bucket_prefix'], user_parameters['child_name'])
            message = f'''Published {user_parameters['inpath']} to {user_parameters['bucket_name']}/{user_parameters['bucket_prefix']}/{user_parameters['child_name']}'''
            put_job_success(job_id)
            logger.info('%s, returning 200 OK respnse', message)
            return {
            "statusCode": 200,
            "headers": {
                "Content-Type": "application/text"
            },
            "body": message
            }
        except KeyError as e:
            codepipeline_client.put_job_failure_result(
                jobId=event["CodePipeline.job"]["id"],
                failureDetails={"type": "ConfigurationError", "message": f"Missing Parameters: {repr(e)}"}
            )
        except Exception as e:
            message = f'Exception occurred {repr(e)} : {traceback.format_exc()}'
            put_job_failure(job_id, message)
            logger.error('%s, returning 417 response', message)
            return {
            "statusCode": 417,
            "headers": {
                "Content-Type": "application/text"
            },
            "body": message
            }
    else:
        message = f'Unexpected event type {type(event)}'
        put_job_failure(job_id, message)
        logger.error('%s, returning 422 response', message)
        return {
            "statusCode": 422,
            "headers": {
                "Content-Type": "application/text"
            },
            "body": message
        }